{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a950650",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963785c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import wandb\n",
    "import cv2 as cv\n",
    "import math \n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import batch_norm\n",
    "import random \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904908de",
   "metadata": {},
   "source": [
    "### Wandb Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40005c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login\n",
    "entity_name=\"me20b030\"\n",
    "\n",
    "project_name=\"Sweep Config\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e91c8",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation paths defined (dataset is present in local computer with the files located at the following locations)\n",
    "train_path = 'C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train'\n",
    "val_path = 'C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val'\n",
    "\n",
    "# Function to display contents\n",
    "def contents(path):\n",
    "    for folder in os.listdir(path):\n",
    "        images=glob.glob((path+'/'+folder+'/*'))\n",
    "        print(\"Class:\",folder, \"total number of images \",len(images))\n",
    "\n",
    "# Function to display images\n",
    "def show_image(img_path):\n",
    "    img=cv.imread(img_path)\n",
    "    img.shape\n",
    "    plt.imshow(img)   \n",
    "    \n",
    "# Function to calculate maxpool dims\n",
    "def maxpool_out_dim(input,filter=2,stride=2):\n",
    "    output_dim=(input-filter)//stride + 1\n",
    "    return output_dim\n",
    "\n",
    "# Function to calculate convolution dims\n",
    "def conv_out_dim(input,filter,stride=1,padding=1):\n",
    "    output_dim=(input-filter+2*padding)//stride + 1\n",
    "    return output_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bd796",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe08426",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train/Amphibia/1c6fca1eb9840e822d5448ee0e2e837e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cecdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_image('C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train/Amphibia/015f03767b5fd30019df9ca7720cb869.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c125ee54",
   "metadata": {},
   "source": [
    "### Data Augmentation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_augmentation():\n",
    "\n",
    "    def __init__(self,augment=True,batch_size=16):\n",
    "        self.train_path='C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train'\n",
    "        self.test_path='C:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val'\n",
    "        self.augment=augment\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "    def transform(self,):\n",
    "        if self.augment==True:\n",
    "            train_transforms = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                                   transforms.RandomVerticalFlip(p=0.5),\n",
    "                                                   transforms.RandomRotation((120)),\n",
    "                                                   transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter()]), p=0.5),\n",
    "                                                   transforms.Resize((224,224)),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "            test_transforms = transforms.Compose([transforms.RandomRotation(120),\n",
    "                                      transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        else:\n",
    "            train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                                   transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "            test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        # Defining the datasets using ImageFolder \n",
    "        train_data = datasets.ImageFolder(self.train_path, transform=train_transforms) \n",
    "        test_data = datasets.ImageFolder(self.test_path, transform=test_transforms)\n",
    "\n",
    "        # Variables defined\n",
    "        num_workers = 0\n",
    "        valid_size = 0.2\n",
    "        num_train = len(train_data)\n",
    "        indices = list(range(num_train))\n",
    "        num_train_class=1000\n",
    "        split = int(np.floor(valid_size * num_train_class))\n",
    "        train_id=[]\n",
    "        valid_id=[]\n",
    "        for i in range(10):\n",
    "            x=i+1\n",
    "            train_idx, valid_idx = indices[i*1000+split:x*1000], indices[i*1000:i*1000+split]\n",
    "            train_id=train_id+train_idx\n",
    "            valid_id=valid_id+valid_idx\n",
    "            \n",
    "        # Split the dataset using ids\n",
    "        train_sampler = SubsetRandomSampler(train_id)\n",
    "        valid_sampler = SubsetRandomSampler(valid_id)\n",
    "\n",
    "        # Loading the data\n",
    "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size,\n",
    "        sampler=train_sampler, num_workers=num_workers)\n",
    "        valid_loader = torch.utils.data.DataLoader(train_data, batch_size=self.batch_size, \n",
    "        sampler=valid_sampler, num_workers=num_workers)\n",
    "        test_loader = torch.utils.data.DataLoader(test_data, batch_size=self.batch_size, \n",
    "        num_workers=num_workers)\n",
    "\n",
    "        return train_loader,valid_loader,test_loader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d53e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of class data augmentation defined to perform transfromations on dataset\n",
    "data_prep=data_augmentation()\n",
    "train_loader,valid_loader,test_loader = data_prep.transform()\n",
    "test_path='D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val'\n",
    "root=pathlib.Path(test_path)\n",
    "\n",
    "# Extracting the class names\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d27c4",
   "metadata": {},
   "source": [
    "### Network Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99606dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNN(nn.Module):\n",
    "    def __init__(self, num_filters, kernel_size, activation,dense_dim, input=224,   dropout=0.1, batch_norm=False):\n",
    "        super(ConvNN,self).__init__()\n",
    "        self.batch_norm=batch_norm\n",
    "        self.activation=activation\n",
    "        self.dense_dim=dense_dim\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=num_filters[0], kernel_size=kernel_size[0], stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=num_filters[0])\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        w_conv=conv_out_dim(224,kernel_size[0])\n",
    "        w_mpool=maxpool_out_dim(w_conv)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=num_filters[0], out_channels=num_filters[1], kernel_size=kernel_size[1], stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=num_filters[1])\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        w_conv=conv_out_dim(w_mpool,kernel_size[1])\n",
    "        w_mpool=maxpool_out_dim(w_conv)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=num_filters[1], out_channels=num_filters[2], kernel_size=kernel_size[2], stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=num_filters[2])\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        w_conv=conv_out_dim(w_mpool,kernel_size[2])\n",
    "        w_mpool=maxpool_out_dim(w_conv)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=num_filters[2], out_channels=num_filters[3], kernel_size=kernel_size[3], stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=num_filters[3])\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        w_conv=conv_out_dim(w_mpool,kernel_size[3])\n",
    "        w_mpool=maxpool_out_dim(w_conv)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=num_filters[3], out_channels=num_filters[4], kernel_size=kernel_size[4], stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=num_filters[4])\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2)\n",
    "        w_conv=conv_out_dim(w_mpool,kernel_size[4])\n",
    "        w_mpool=maxpool_out_dim(w_conv)\n",
    "        w_out=num_filters[4]*w_mpool*w_mpool\n",
    "        self.w_out=w_out\n",
    "\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.Flatten=nn.Flatten(start_dim=1,end_dim=-1)\n",
    "        self.fc1 = nn.Linear(in_features=w_out, out_features=10)\n",
    "\n",
    "      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.batch_norm==True:\n",
    "            x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        if self.batch_norm==True:\n",
    "            x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        if self.batch_norm==True:\n",
    "            x = self.bn3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        if self.batch_norm==True:\n",
    "            x = self.bn4(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        if self.batch_norm==True:\n",
    "            x = self.bn5(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        x = x.view(-1,self.w_out)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e67298",
   "metadata": {},
   "source": [
    "### Sweep Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes', \n",
    "    'metric': {\n",
    "      'name': 'Validation_Accuracy',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'num_dense_dim': {\n",
    "            'values': [64,256]\n",
    "        },\n",
    "        'num_filters' : {\n",
    "           'values' : [[32,32,32,32,32],[32,64,64,128,128],[128,128,64,64,32],[16,32,64,128,256]]\n",
    "        },\n",
    "      'kernel_size' : {\n",
    "         'values' : [[3,5,5,7,7], [7,7,5,3,3], [3,3,3,3,3]]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.2, 0.3, 0.4]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [1e-3, 1e-4]\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['relu','elu','leaky_relu']\n",
    "        },\n",
    "        'batch_norm':{\n",
    "            'values': [True,False]\n",
    "        },\n",
    "        'augment': {\n",
    "            'values': [True,False]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [16, 32]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc12bdf",
   "metadata": {},
   "source": [
    "### Training Sweep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(kernel_size=[3,3,3,3,3], num_filters=[128,128,64,64,32], dense_dim=64, activation=nn.functional.relu,dropout=0.3,batch_norm=False,augment=True, batch_size=16 ,n_epochs=15,learning_rate= 1e-4):\n",
    "  \n",
    "    config_defaults = {\n",
    "        'num_dense_dim': dense_dim,\n",
    "        'num_filters' : [128,128,64,64,32],\n",
    "        'kernel_size' : [3,3,3,3,3],\n",
    "        'dropout': dropout,\n",
    "        'learning_rate': learning_rate,\n",
    "        'activation': \"relu\",\n",
    "        'batch_norm': batch_norm,\n",
    "        'batch_size' : batch_size,\n",
    "        'optimizer': 'Adam',\n",
    "        'augment': augment\n",
    "    }\n",
    " \n",
    "    # Initializing the wandb run\n",
    "    wandb.init(config=config_defaults)\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Checking for activation fucntions  AVAILABLE ACTIVATION FUNCTIONS: [ RELU, SILU, ELU, LEAKYRELU]\n",
    "    if config.activation==\"relu\":\n",
    "        activation=nn.functional.relu\n",
    "    elif config.activation=='elu':\n",
    "        activation=nn.functional.elu\n",
    "    elif config.activation=='silu':\n",
    "        activation=nn.functional.silu\n",
    "    elif config.activation=='leaky_relu':\n",
    "        activation=nn.functional.leaky_relu\n",
    "\n",
    "    # Device availability\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = ConvNN(config.num_filters,config.kernel_size,activation,config.num_dense_dim, config.dropout,config.batch_norm).to(device)\n",
    "    \n",
    "    # OPtimizer and loss functions defined\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Data augmentation added and loaded\n",
    "    data_prep=data_augmentation(config.augment,config.batch_size)\n",
    "    train_loader,valid_loader,test_loader = data_prep.transform()\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "  \n",
    "\n",
    "    ep=0\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        #scheduler.step()\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "\n",
    "    # Training the model\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()     \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        optimizer.zero_grad()\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        ps=nn.functional.softmax(output,dim=1)\n",
    "        top_p,top_c= ps.topk(1,dim=1)\n",
    "        equals= target == top_c.view(*target.shape)\n",
    "        val_accuracy+= equals.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    # Loss and accuracies calculated\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    val_accuracy = val_accuracy/len(valid_loader)\n",
    "\n",
    "    # Custom name defined for wandb run\n",
    "    name_run=\"run\" + '_' + str(config.activation) + '_' +str(config.num_dense_dim) + '_aug:' + str(config.augment)\n",
    "    wandb.run.name = name_run\n",
    "    wandb_log=True\n",
    "\n",
    "    if(wandb_log==True):\n",
    "        log_dict = {\"Train_loss\": train_loss, \"Validation_loss\": valid_loss, \"Validation_Accuracy\": val_accuracy}     \n",
    "        ep=ep+1\n",
    "        print('Epoch: {} \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f} \\tValidation Accuracy: {:.5f}'.format(ep,\n",
    "        train_loss, valid_loss,val_accuracy))       \n",
    "        wandb.log(log_dict)\n",
    "       \n",
    "     \n",
    "    wandb.run.save()\n",
    "    wandb.run.finish()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e4875",
   "metadata": {},
   "source": [
    "### Running Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc530f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_sweep(entity_name, project_name,kernel_size=[3,3,3,3,3], num_filters=[128,128,64,64,32], dense_dim=64, activation=nn.functional.relu,dropout=0.3,batch_norm=False,augment=True, batch_size=16 ,n_epochs=20,learning_rate= 1e-4):\n",
    "    sweep_id=wandb.sweep(sweep_config, entity=entity_name, project=project_name)\n",
    "    wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3bf6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=entity_name, project=project_name)\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870572ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 4):\n",
    "     \n",
    "    #scheduler.step()\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    # Setting up parameters\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()     \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "       \n",
    "    # Evaluating the model\n",
    "    model.eval()\n",
    "    for data, target in valid_loader:\n",
    "        optimizer.zero_grad()\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        ps=nn.functional.softmax(output,dim=1)\n",
    "        top_p,top_c= ps.topk(1,dim=1)\n",
    "        equals= target == top_c.view(*target.shape)\n",
    "        val_accuracy+= equals.type(torch.FloatTensor).mean()\n",
    "    \n",
    "\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "    val_accuracy = val_accuracy/len(valid_loader)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.6f}'.format(epoch+15,\n",
    "        train_loss, valid_loss,val_accuracy))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4ec57",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82672d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "model.eval()\n",
    "test_accuracy=0.0\n",
    "for data, target in test_loader:\n",
    "    \n",
    "        # Setting optimizer to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # GPU run checkpoint\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # output, criterion and loss functions defined\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        ps=nn.functional.softmax(output,dim=1)\n",
    "        top_p,top_c= ps.topk(1,dim=1)\n",
    "        \n",
    "        # Test accuracy calculated\n",
    "        equals= target == top_c.view(*target.shape)\n",
    "        test_accuracy+= equals.type(torch.FloatTensor).mean()\n",
    "    \n",
    "test_accuracy = test_accuracy/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEST ACCURACY:\", np.float32(test_accuracy), \" is the best on our dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9fd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes zipped into a dictionary and visualised\n",
    "label_dict=dict(zip(list(range(len(classes))),classes))\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ff673",
   "metadata": {},
   "source": [
    "### Grid Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8377f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining test transforms for augmentation\n",
    "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "fig, axs = plt.subplots(3, 10, figsize=(20,7))\n",
    "\n",
    "model.eval()\n",
    "class_ = list(map(lambda x: x.split(\"/\")[-1], glob.glob('D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train/*')))\n",
    "idx=list(range(len(class_)))\n",
    "label_dict=dict(zip(idx,class_))\n",
    "for i in range(3):\n",
    "            classes = random.sample(os.listdir('D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val'), k=3)\n",
    "            path = os.path.join('D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val', classes[i])\n",
    "            img_path = random.sample(os.listdir(path), 10)\n",
    "            \n",
    "            \n",
    "            imgs = [test_transforms(Image.open(os.path.join(path,i)).convert('RGB')) for i in img_path]\n",
    "            for c, img in enumerate(imgs):\n",
    "                    optimizer.zero_grad()\n",
    "                    if train_on_gpu:\n",
    "                         img_input = img.to(device)\n",
    "                    pred = nn.functional.softmax(model(img_input.unsqueeze(0)), dim=1)\n",
    "                    prob, idx = torch.max(pred,dim=1)\n",
    "                    axs[i, c].set_title(f\"{label_dict[idx.item()]}:{prob.item():0.2f}\")\n",
    "                    axs[i, c].imshow(img.permute(1,2,0).numpy())\n",
    "                    axs[i, c].set(ylabel=classes[i])\n",
    "                    axs[i, c].set_xticks([])\n",
    "                    axs[i, c].set_yticks([])\n",
    "                    \n",
    "            \n",
    "for ax in axs.flat:\n",
    "     ax.label_outer()\n",
    "fig.supylabel(\"True Labels\")\n",
    "fig.supxlabel(\"Predicted Labels\")\n",
    "plt.savefig(\"./1.png\")\n",
    "# wandb.log({f\"Question-4\": wandb.Image(Image.open(\"./1.png\").convert(\"RGB\"))})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e74396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
