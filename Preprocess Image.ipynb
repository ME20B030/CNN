{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a921420a",
   "metadata": {},
   "source": [
    "$IMPORTING$ $ESSENTIAL$ $LIBRARIES$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6862c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "torch.manual_seed(0)\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92090b0",
   "metadata": {},
   "source": [
    "$HYPERPARAMETERS$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00947d5",
   "metadata": {},
   "source": [
    "$SPECIAL$ $FUNCTIONS$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415232a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting parameters from user\n",
    "def get_parameters():\n",
    "    kernel_ = []\n",
    "    for i in range(5):\n",
    "        kernel_.append(input(print(f\"Enter the number of kernel filters needed in your neural network layer{i}: \")))\n",
    "    return kernel_\n",
    "\n",
    "# Function for showing examples\n",
    "def show_example(img):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n",
    "    \n",
    "# Function for showing data\n",
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE),cmap = 'gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda63ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMS \n",
    "# Transforms or data augmentation\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "    transforms.RandomRotation((-30,30)),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee163ab9",
   "metadata": {},
   "source": [
    "$DATASET$   $LOADING$   $AND$   $SPLITTING$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46049c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation paths defined (dataset is present in local computer with the files located at the following locations)\n",
    "train_path = 'D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/train'\n",
    "val_path = 'D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K/val'\n",
    "data_path = 'D:/LowLight_Colorization/Datasets/inaturalist/nature_12K/inaturalist_12K'\n",
    "\n",
    "# Train and validation datasets defined\n",
    "train_dataset = ImageFolder(train_path, transform=transform_)\n",
    "val_dataset = ImageFolder(root = val_path, transform = transform_)\n",
    "\n",
    "# Splitting the training data into 80-20 ratio for hyperparameter sweeping in wandb\n",
    "train_set, sweep_set = torch.utils.data.random_split(train_dataset, [7999, 2000])\n",
    "\n",
    "\n",
    "\n",
    "#Train and validation data loader defined\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#Taking and displaying first class first image\n",
    "show_data(val_dataset[0][0])\n",
    "\n",
    "# train_loader = DataLoader(data_path, batch_size=32, shuffle=True)\n",
    "# augmented_loader = augment_dataloader(train_loader, num_augmentations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec6985",
   "metadata": {},
   "source": [
    "### PART-B Transfer Learning in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0d55f",
   "metadata": {},
   "source": [
    "$MODEL:$ $MobileNet$ $V3$\n",
    "\n",
    "Here we train the model with pre-weights loaded and freezing them.\n",
    "In the last part of the model, Fully Connected layers are custom defined \n",
    "and the output layer is defined based on our use case, here 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55cfc2d",
   "metadata": {},
   "source": [
    "$Mobilenet$ $V3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Vgg-19 model\n",
    "model_v3 = models.mobilenet_v3_small(pretrained=True)\n",
    "model_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6c2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing the weights of the model \n",
    "for param in model_v3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Defining final layers to be flexible (setting gradient to be True for training)\n",
    "model_v3.classifier[0].requires_grad = True\n",
    "model_v3.classifier[3].requires_grad = True\n",
    "model_v3.classifier[0] = nn.Linear(576,1024)\n",
    "model_v3.classifier[3] = nn.Linear(1024,10)\n",
    "model_v3.classifier[2] = nn.Dropout(p=0.4, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826e98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobilenetV3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobilenetV3, self).__init__()\n",
    "        self.mobilenetv3 = models.mobilenet_v3_small(pretrained=True)\n",
    "        self.fc = nn.Linear(576, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mobilenetv3.features(x)\n",
    "        x = self.mobilenetv3.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bdcd9",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Model, loss function, and optimizer are defined\n",
    "model = MobilenetV3()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# training the model\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    total_val = 0\n",
    "    correct_val = 0\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print('[%d, %5d] train loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('[%d] train acc: %.3f, val acc: %.3f' % (epoch + 1, 100 * correct_train / total_train, 100 * correct_val / total_val))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ffae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
